{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Final Prediction Computation\n",
    "\n",
    "This notebook generates the final model predictions and formats them for submission on Codabench.\n",
    "\n",
    "The evaluation dataset comprises data from 39 stations included in the training set and 13 stations exclusive to the evaluation set.\n",
    "\n",
    "<img src=\"../images/notebook-4.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n",
    "\n",
    "### 1. Imports\n",
    "\n",
    "Starts by importing the necessary libraries, configuring environment paths, and loading custom utility functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.utils.model import load_models_auto\n",
    "from src.utils.analysis import create_predict_function, create_quantile_function\n",
    "from src.utils.model import load_models_auto, XGBQuantileRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines constants :\n",
    "\n",
    "- _DATASET_DIR_ must be the directory where you unzip the _zenodo_ dataset.\n",
    "- _EVAL_DIR_ will be used to store inference / evaluation data it must be the same as the one defined in _01 Training > 01 - Modelisation_\n",
    "- _FINAL_MODEL_ will be used to store inference / evaluation data\n",
    "\n",
    "FINAL_MODEL describe the model that will be loaded if you use auto-loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDS_DIR: ../../../data/evaluation/full_pca/xgb/\n"
     ]
    }
   ],
   "source": [
    "ALPHA = 0.1\n",
    "NUMBER_OF_WEEK = 4\n",
    "USE_AUTO_SCAN = True  # Toggle this to switch between the loading of the last model of the manual load of a specific model\n",
    "FINAL_MODEL = \"xgb\"\n",
    "DATASET_SPEC = \"full_pca\"\n",
    "\n",
    "EVAL_DIR = \"../../../data/evaluation/\"\n",
    "MODEL_DIR = f\"../../../models/{DATASET_SPEC}/\"\n",
    "\n",
    "PREDS_DIR = f\"{EVAL_DIR}{DATASET_SPEC}/{FINAL_MODEL}/\"\n",
    "\n",
    "print(f\"PREDS_DIR: {PREDS_DIR}\")\n",
    "os.makedirs(PREDS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and models Loading\n",
    "\n",
    "Loading of the inference dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "inference_data = pd.read_csv(f\"{EVAL_DIR}dataset_{DATASET_SPEC}.csv\")\n",
    "inference_data = inference_data.set_index(\"ObsDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_code', 'latitude', 'longitude', 'catchment', 'altitude',\n",
       "       'precipitations', 'temperatures', 'soil_moisture', 'evaporation',\n",
       "       'precipitation_region', 'temperature_region', 'soil_moisture_region',\n",
       "       'evaporation_region', 'precipitation_zone', 'temperature_zone',\n",
       "       'soil_moisture_zone', 'evaporation_zone', 'precipitation_sector',\n",
       "       'temperature_sector', 'soil_moisture_sector', 'evaporation_sector',\n",
       "       'precipitation_sub_sector', 'temperature_sub_sector',\n",
       "       'soil_moisture_sub_sector', 'evaporation_sub_sector',\n",
       "       'water_flow_lag_1w', 'water_flow_lag_2w', 'precipitations_lag_1w',\n",
       "       'temperatures_lag_1w', 'evaporation_lag_1w',\n",
       "       'precipitation_region_lag_1w', 'temperature_region_lag_1w',\n",
       "       'evaporation_region_lag_1w', 'precipitation_zone_lag_1w',\n",
       "       'temperature_zone_lag_1w', 'evaporation_zone_lag_1w',\n",
       "       'precipitation_sector_lag_1w', 'temperature_sector_lag_1w',\n",
       "       'evaporation_sector_lag_1w', 'precipitation_sub_sector_lag_1w',\n",
       "       'temperature_sub_sector_lag_1w', 'evaporation_sub_sector_lag_1w',\n",
       "       'north_hemisphere', 'soil_pca_1', 'soil_pca_2', 'soil_pca_3',\n",
       "       'soil_pca_4', 'soil_pca_5', 'soil_pca_6', 'soil_pca_7', 'soil_pca_8',\n",
       "       'soil_pca_9', 'soil_pca_10', 'month_sin', 'month_cos', 'season_sin',\n",
       "       'season_cos', 'region_cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the final models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models based on conditions\n",
    "final_models = []\n",
    "if FINAL_MODEL == \"mapie\":\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"mapie_quantile\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(\n",
    "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-04_week0.pkl\"\n",
    "            )\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(\n",
    "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-11_week1.pkl\"\n",
    "            )\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(\n",
    "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week2.pkl\"\n",
    "            )\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(\n",
    "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week3.pkl\"\n",
    "            )\n",
    "        )\n",
    "elif FINAL_MODEL == \"qrf\":\n",
    "\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"qrf_quantile\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
    "        )\n",
    "elif FINAL_MODEL == \"lgbm\":\n",
    "\n",
    "    if USE_AUTO_SCAN:\n",
    "        models_low = load_models_auto(\"lgbm_quantile_q0.05\", f\"{MODEL_DIR}final/\")\n",
    "        models_med = load_models_auto(\"lgbm_quantile_q0.5\", f\"{MODEL_DIR}final/\")\n",
    "        models_high = load_models_auto(\"lgbm_quantile_q0.95\", f\"{MODEL_DIR}final/\")\n",
    "        final_models = [[] for _ in range(NUMBER_OF_WEEK)]\n",
    "        final_models[0] = [models_low[0], models_med[0], models_high[0]]\n",
    "        final_models[1] = [models_low[1], models_med[1], models_high[1]]\n",
    "        final_models[2] = [models_low[2], models_med[2], models_high[2]]\n",
    "        final_models[3] = [models_low[3], models_med[3], models_high[3]]\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
    "        )\n",
    "elif FINAL_MODEL == \"ebm_ensemble\":\n",
    "    print(\"Loading EBM Ensemble\")\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"ebm_ensemble\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-04_week0.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-11_week1.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-17_week2.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-17_week3.pkl\")\n",
    "        )\n",
    "elif FINAL_MODEL == \"deep_ensemble\":\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"deep_ensemble\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-04_week0.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-11_week1.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-17_week2.pkl\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-17_week3.pkl\")\n",
    "        )\n",
    "elif FINAL_MODEL == \"xgb\":\n",
    "    if USE_AUTO_SCAN:\n",
    "        final_models = load_models_auto(\"xgb\", f\"{MODEL_DIR}final/\")\n",
    "    else:\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/xgb_2025-03-18_23-50-32_week_0\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/xgb_2025-03-18_23-50-32_week_1\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/xgb_2025-03-18_23-50-32_week_2\")\n",
    "        )\n",
    "        final_models.append(\n",
    "            joblib.load(f\"{MODEL_DIR}final/xgb_2025-03-18_23-50-32_week_3\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predictions computation\n",
    "\n",
    "Evaluation data include a spatio-temporal split and a temporal only split.\n",
    "\n",
    "<img src=\"../images/eval.png\" alt=\"Experiment Diagram\" style=\"width:50%;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "model : xgb\n",
      "xgb\n",
      "model : xgb\n",
      "xgb\n",
      "model : xgb\n",
      "xgb\n",
      "model : xgb\n"
     ]
    }
   ],
   "source": [
    "predictions = inference_data[[\"station_code\"]].copy()\n",
    "y_pred_test_quantile = {}\n",
    "y_pred_test = {}\n",
    "X_test = inference_data.drop(columns=[\"station_code\"])\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "\n",
    "    if FINAL_MODEL == \"qrf\":\n",
    "        # reorder the columns\n",
    "        X_test = X_test[final_models[0].feature_names_in_]\n",
    "\n",
    "    if FINAL_MODEL == \"xgb\":\n",
    "        X_test = (\n",
    "            X_test.drop(columns=[\"north_hemisphere\"])\n",
    "            if \"north_hemisphere\" in X_test.columns\n",
    "            else X_test\n",
    "        )\n",
    "    print(FINAL_MODEL)\n",
    "    predict_adjusted = create_predict_function(final_models, i, FINAL_MODEL)\n",
    "    quantile_adjusted = create_quantile_function(final_models, i, FINAL_MODEL, ALPHA)\n",
    "\n",
    "    y_pred_test[i] = predict_adjusted(X_test)\n",
    "    y_pred_test_quantile[i] = quantile_adjusted(X_test)\n",
    "\n",
    "    if FINAL_MODEL == \"xgb\":\n",
    "        y_pred_test_quantile[i][:, 0].fill(0)\n",
    "\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "    predictions[f\"week_{i}_pred\"] = y_pred_test[i]\n",
    "    predictions[f\"week_{i}_sup\"] = y_pred_test_quantile[i][:, 1]\n",
    "    predictions[f\"week_{i}_inf\"] = y_pred_test_quantile[i][:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Saving of the predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving of the predictions as a csv file\n",
    "\n",
    "> The file must be named `predictions.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to a csv file\n",
    "predictions[\"ObsDate\"] = X_test.index\n",
    "predictions.to_csv(f\"{PREDS_DIR}predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression of the submission file.\n",
    "\n",
    "> The file need to be compress for Codabench.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP file containing predictions.csv\n",
    "with zipfile.ZipFile(f\"{PREDS_DIR}predictions.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(f\"{PREDS_DIR}predictions.csv\", \"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to submit go to codabench and submit the zip file that have been generated in My Submissions > Phase 1.\n",
    "\n",
    "You don't have to use this notebook to submit but the file file format must includes the following columns:\n",
    "\n",
    "- station_code: Identification code of the station.\n",
    "- ObsDate: Date of the prediction.\n",
    "- for every week of prediction i from 0 to 3 :\n",
    "  - week_i_pred\n",
    "  - week_i_inf\n",
    "  - week_i_sup\n",
    "\n",
    "Save the dataset as a CSV file named predictions.csv.\n",
    "\n",
    "> The file must be named predictions.csv, but the .zip file can have any name.\n",
    "\n",
    "Compress the CSV file into a .zip archive.\n",
    "\n",
    "> You cannot submit an uncompressed file. Ensure that the software you use does not create a subfolder inside the archive.\n",
    "\n",
    "Submit your file in [Codabench](https://www.codabench.org/competitions/4335):\n",
    "\n",
    "> My Submissions > Phase 1 (keep all the tasks selected):\n",
    "\n",
    "<img src=\"../images/submissions.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
