{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objective: Final Prediction Computation\n",
        "\n",
        "This notebook generates the final model predictions and formats them for submission on Codabench.\n",
        "\n",
        "The evaluation dataset comprises data from 39 stations included in the training set and 13 stations exclusive to the evaluation set.\n",
        "\n",
        "<img src=\"../images/notebook-4.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n",
        "\n",
        "### 1. Imports\n",
        "\n",
        "Starts by importing the necessary libraries, configuring environment paths, and loading custom utility functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
        "\n",
        "from src.utils.model import load_models_auto\n",
        "from src.utils.analysis import create_predict_function, create_quantile_function\n",
        "from src.utils.model import load_models_auto\n",
        "from src.utils.model import XGBQuantileRegressor, XGBQRFModel, XGBQRF_SimpleModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defines constants :\n",
        "\n",
        "- _DATASET_DIR_ must be the directory where you unzip the _zenodo_ dataset.\n",
        "- _EVAL_DIR_ will be used to store inference / evaluation data it must be the same as the one defined in _01 Training > 01 - Modelisation_\n",
        "- _FINAL_MODEL_ will be used to store inference / evaluation data\n",
        "\n",
        "FINAL_MODEL describe the model that will be loaded if you use auto-loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREDS_DIR: ../../../data/evaluation/custom_dataset_5/qrf/\n"
          ]
        }
      ],
      "source": [
        "ALPHA = 0.1\n",
        "NUMBER_OF_WEEK = 4\n",
        "USE_AUTO_SCAN = True  # Toggle this to switch between the loading of the last model of the manual load of a specific model\n",
        "FINAL_MODEL = \"qrf\"\n",
        "DATASET_TRANSFORMS = [\n",
        "    \"rm_gnv_st\",\n",
        "    \"pca\",\n",
        "    \"snow_index\",\n",
        "    # \"oh_enc_date\",\n",
        "    \"cyc_enc_date\",\n",
        "    \"clust_index\",\n",
        "    \"scl_feat\",\n",
        "    # \"scl_feat_wl\",  # Scale all except waterflow lag\n",
        "    \"scl_catch\",\n",
        "]\n",
        "\n",
        "PCA_THRESHOLD = 0.98\n",
        "N_CLUSTER = 10\n",
        "\n",
        "DATASET_SPEC = \"_\".join(DATASET_TRANSFORMS)\n",
        "DATASET_SPEC = \"custom_dataset_4\"\n",
        "\n",
        "if \"pca\" in DATASET_TRANSFORMS:\n",
        "    DATASET_SPEC += f\"_pct_{PCA_THRESHOLD}\"\n",
        "\n",
        "if \"clust_index\" in DATASET_TRANSFORMS:\n",
        "    DATASET_SPEC += f\"_geocl_{N_CLUSTER}\"\n",
        "\n",
        "if \"clust_hydro\" in DATASET_TRANSFORMS:\n",
        "    DATASET_SPEC += f\"_hydcl_{N_CLUSTER}\"\n",
        "\n",
        "DATASET_SPEC = \"custom_dataset_5\"\n",
        "\n",
        "ADJUSTED_BONDS = False\n",
        "\n",
        "EVAL_DIR = \"../../../data/evaluation/\"\n",
        "EVAL_DIR_MINI = \"../../../data/evaluation_mini/\"\n",
        "MODEL_DIR = f\"../../../models/{DATASET_SPEC}/\"\n",
        "\n",
        "PREDS_DIR = f\"{EVAL_DIR}{DATASET_SPEC}/{FINAL_MODEL}/\"\n",
        "COMPUTE_MINICHALLENGE = True\n",
        "\n",
        "print(f\"PREDS_DIR: {PREDS_DIR}\")\n",
        "os.makedirs(PREDS_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data and models Loading\n",
        "\n",
        "Loading of the inference dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "inference_data = pd.read_csv(f\"{EVAL_DIR}{DATASET_SPEC}.csv\")\n",
        "inference_data = inference_data.set_index(\"ObsDate\")\n",
        "\n",
        "if COMPUTE_MINICHALLENGE:\n",
        "    inference_data_mini = pd.read_csv(f\"{EVAL_DIR_MINI}{DATASET_SPEC}.csv\")\n",
        "    inference_data_mini = inference_data_mini.set_index(\"ObsDate\")\n",
        "    inference_data = pd.concat([inference_data, inference_data_mini], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1390, 42)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inference_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading of the final models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load models based on conditions\n",
        "final_models = []\n",
        "if FINAL_MODEL == \"mapie\":\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"mapie_quantile\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(\n",
        "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-04_week0.pkl\"\n",
        "            )\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(\n",
        "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-11_week1.pkl\"\n",
        "            )\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(\n",
        "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week2.pkl\"\n",
        "            )\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(\n",
        "                f\"{MODEL_DIR}final/mapie_quantile_2025-01-17_15-15-17_week3.pkl\"\n",
        "            )\n",
        "        )\n",
        "elif FINAL_MODEL == \"qrf\":\n",
        "\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"qrf_quantile\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"gpr\":\n",
        "    selected_kernel = [\n",
        "        \"rbf\",\n",
        "        # \"\",\n",
        "        # \"\",\n",
        "    ]\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\n",
        "            f\"gpr_quantile_{\"\".join(selected_kernel)}\", f\"{MODEL_DIR}final/\"\n",
        "        )\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "\n",
        "elif FINAL_MODEL == \"gbr\":\n",
        "\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"gbr_quantile\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"qrf_voting\":\n",
        "\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"qrf_voting_quantile\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"qrf_bagging\":\n",
        "\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"qrf_bagging_quantile\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"lgbm\":\n",
        "\n",
        "    if USE_AUTO_SCAN:\n",
        "        models_low = load_models_auto(\"lgbm_quantile_q0.05\", f\"{MODEL_DIR}final/\")\n",
        "        models_med = load_models_auto(\"lgbm_quantile_q0.5\", f\"{MODEL_DIR}final/\")\n",
        "        models_high = load_models_auto(\"lgbm_quantile_q0.95\", f\"{MODEL_DIR}final/\")\n",
        "        final_models = [[] for _ in range(NUMBER_OF_WEEK)]\n",
        "        final_models[0] = [models_low[0], models_med[0], models_high[0]]\n",
        "        final_models[1] = [models_low[1], models_med[1], models_high[1]]\n",
        "        final_models[2] = [models_low[2], models_med[2], models_high[2]]\n",
        "        final_models[3] = [models_low[3], models_med[3], models_high[3]]\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/qrf_quantile_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"ebm_ensemble\":\n",
        "    print(\"Loading EBM Ensemble\")\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"ebm_ensemble\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/ebm_ensemble_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"deep_ensemble\":\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"deep_ensemble\", f\"{MODEL_DIR}final/\")\n",
        "    else:\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-04_week0.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-11_week1.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-17_week2.pkl\")\n",
        "        )\n",
        "        final_models.append(\n",
        "            joblib.load(f\"{MODEL_DIR}final/deep_ensemble_2025-01-17_15-15-17_week3.pkl\")\n",
        "        )\n",
        "elif FINAL_MODEL == \"xgb\":\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"xgb\", f\"{MODEL_DIR}final/\")\n",
        "elif FINAL_MODEL == \"xgb_qrf\":\n",
        "    if USE_AUTO_SCAN:\n",
        "        final_models = load_models_auto(\"xgb_qrf\", f\"{MODEL_DIR}final/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[RandomForestQuantileRegressor(max_depth=40, max_features=None,\n",
              "                               min_samples_leaf=23, min_samples_split=11,\n",
              "                               n_estimators=35, random_state=42),\n",
              " RandomForestQuantileRegressor(max_depth=40, max_features=None,\n",
              "                               min_samples_leaf=23, min_samples_split=11,\n",
              "                               n_estimators=35, random_state=42),\n",
              " RandomForestQuantileRegressor(max_depth=40, max_features=None,\n",
              "                               min_samples_leaf=23, min_samples_split=11,\n",
              "                               n_estimators=35, random_state=42),\n",
              " RandomForestQuantileRegressor(max_depth=40, max_features=None,\n",
              "                               min_samples_leaf=23, min_samples_split=11,\n",
              "                               n_estimators=35, random_state=42)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Predictions computation\n",
        "\n",
        "Evaluation data include a spatio-temporal split and a temporal only split.\n",
        "\n",
        "<img src=\"../images/eval.png\" alt=\"Experiment Diagram\" style=\"width:50%;\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qrf\n",
            "model : qrf\n",
            "qrf\n",
            "model : qrf\n",
            "qrf\n",
            "model : qrf\n",
            "qrf\n",
            "model : qrf\n"
          ]
        }
      ],
      "source": [
        "predictions = inference_data[[\"station_code\"]].copy()\n",
        "y_pred_test_quantile = {}\n",
        "y_pred_test = {}\n",
        "X_test = inference_data.drop(columns=[\"station_code\"])\n",
        "for i in range(NUMBER_OF_WEEK):\n",
        "\n",
        "    if FINAL_MODEL == \"qrf\":\n",
        "        # reorder the columns\n",
        "        X_test = X_test[final_models[0].feature_names_in_]\n",
        "\n",
        "    # if FINAL_MODEL == \"xgb\":\n",
        "    #     X_test = (\n",
        "    #         X_test.drop(columns=[\"north_hemisphere\"])\n",
        "    #         if \"north_hemisphere\" in X_test.columns\n",
        "    #         else X_test\n",
        "    #     )\n",
        "    print(FINAL_MODEL)\n",
        "    predict_adjusted = create_predict_function(final_models, i, FINAL_MODEL)\n",
        "    quantile_adjusted = create_quantile_function(final_models, i, FINAL_MODEL, ALPHA)\n",
        "\n",
        "    y_pred_test[i] = predict_adjusted(X_test)\n",
        "    y_pred_test_quantile[i] = quantile_adjusted(X_test)\n",
        "\n",
        "    if FINAL_MODEL == \"lgbm\":\n",
        "        y_pred_test_quantile[i][y_pred_test_quantile[i] < 0] = 0\n",
        "        y_pred_test[i][y_pred_test[i] < 0] = 0\n",
        "\n",
        "    if FINAL_MODEL == \"xgb\":\n",
        "        y_pred_test_quantile[i][:, 0] *= 0.98\n",
        "        y_pred_test_quantile[i][:, 1] *= 1.02\n",
        "\n",
        "for i in range(NUMBER_OF_WEEK):\n",
        "    predictions[f\"week_{i}_pred\"] = y_pred_test[i]\n",
        "    predictions[f\"week_{i}_sup\"] = y_pred_test_quantile[i][:, 1]\n",
        "    predictions[f\"week_{i}_inf\"] = y_pred_test_quantile[i][:, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Saving of the predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving of the predictions as a csv file\n",
        "\n",
        "> The file must be named `predictions.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>week_1_inf</th>\n",
              "      <th>week_1_pred</th>\n",
              "      <th>week_1_sup</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ObsDate</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2004-02-01</th>\n",
              "      <td>16.200000</td>\n",
              "      <td>42.695014</td>\n",
              "      <td>105.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-04-25</th>\n",
              "      <td>7.964000</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>37.841737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-07-18</th>\n",
              "      <td>5.562714</td>\n",
              "      <td>14.357143</td>\n",
              "      <td>26.005714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-10-10</th>\n",
              "      <td>2.262857</td>\n",
              "      <td>4.245714</td>\n",
              "      <td>15.801950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-01-02</th>\n",
              "      <td>6.881714</td>\n",
              "      <td>19.485714</td>\n",
              "      <td>43.464286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-04-20</th>\n",
              "      <td>409.402469</td>\n",
              "      <td>912.210129</td>\n",
              "      <td>1982.555781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-07-13</th>\n",
              "      <td>248.192500</td>\n",
              "      <td>313.311757</td>\n",
              "      <td>476.827943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-10-05</th>\n",
              "      <td>102.253059</td>\n",
              "      <td>169.958971</td>\n",
              "      <td>380.496069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-28</th>\n",
              "      <td>760.839751</td>\n",
              "      <td>1247.551329</td>\n",
              "      <td>2345.008273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-22</th>\n",
              "      <td>239.049673</td>\n",
              "      <td>577.207243</td>\n",
              "      <td>1230.389654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1390 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            week_1_inf  week_1_pred   week_1_sup\n",
              "ObsDate                                         \n",
              "2004-02-01   16.200000    42.695014   105.428571\n",
              "2004-04-25    7.964000    21.600000    37.841737\n",
              "2004-07-18    5.562714    14.357143    26.005714\n",
              "2004-10-10    2.262857     4.245714    15.801950\n",
              "2005-01-02    6.881714    19.485714    43.464286\n",
              "...                ...          ...          ...\n",
              "2014-04-20  409.402469   912.210129  1982.555781\n",
              "2014-07-13  248.192500   313.311757   476.827943\n",
              "2014-10-05  102.253059   169.958971   380.496069\n",
              "2014-12-28  760.839751  1247.551329  2345.008273\n",
              "2015-03-22  239.049673   577.207243  1230.389654\n",
              "\n",
              "[1390 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[[\"week_1_inf\",\"week_1_pred\", \"week_1_sup\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.036542857142857155)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = predictions[\"week_1_pred\"] - predictions[\"week_1_inf\"]\n",
        "test.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the predictions to a csv file\n",
        "predictions[\"ObsDate\"] = X_test.index\n",
        "predictions.to_csv(f\"{PREDS_DIR}predictions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compression of the submission file.\n",
        "\n",
        "> The file need to be compress for Codabench.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a ZIP file containing predictions.csv\n",
        "with zipfile.ZipFile(f\"{PREDS_DIR}predictions.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
        "    zipf.write(f\"{PREDS_DIR}predictions.csv\", \"predictions.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are ready to submit go to codabench and submit the zip file that have been generated in My Submissions > Phase 1.\n",
        "\n",
        "You don't have to use this notebook to submit but the file file format must includes the following columns:\n",
        "\n",
        "- station_code: Identification code of the station.\n",
        "- ObsDate: Date of the prediction.\n",
        "- for every week of prediction i from 0 to 3 :\n",
        "  - week_i_pred\n",
        "  - week_i_inf\n",
        "  - week_i_sup\n",
        "\n",
        "Save the dataset as a CSV file named predictions.csv.\n",
        "\n",
        "> The file must be named predictions.csv, but the .zip file can have any name.\n",
        "\n",
        "Compress the CSV file into a .zip archive.\n",
        "\n",
        "> You cannot submit an uncompressed file. Ensure that the software you use does not create a subfolder inside the archive.\n",
        "\n",
        "Submit your file in [Codabench](https://www.codabench.org/competitions/4335):\n",
        "\n",
        "> My Submissions > Phase 1 (keep all the tasks selected):\n",
        "\n",
        "<img src=\"../images/submissions.png\" alt=\"Experiment Diagram\" style=\"width:75%;\" style=\"text-align:center;\" />\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
