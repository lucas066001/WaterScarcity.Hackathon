{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals: Performance comparison of several models on a fixed testing set\n",
    "\n",
    "This notebook aims to give you tools for a basic performance c\n",
    "\n",
    "# 1. Data Import and Setup\n",
    "\n",
    "Imports necessary libraries, sets up environment paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..','..','..','..')))\n",
    "\n",
    "from src.utils.model import load_models_auto, compare_models_per_station\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines constants :\n",
    "* INPUT_DIR must be the same as the one defined in *00 Preprocessing/Feature Engineering*.\n",
    "* MODEL_DIR must be the same as the one defined in *Splited Dataset/02 -Training*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_AUTO_SCAN = True\n",
    "NUMBER_OF_WEEK = 4\n",
    "INPUT_DIR = \"../../../../data/input/\"\n",
    "MODEL_DIR = \"../../../../models/exploration/\"\n",
    "ALPHA = 0.1\n",
    "\n",
    "# columns to dropÂ : target at different horizon, station_code, and features removed from Feature Selection\n",
    "TO_DROP = [\"water_flow_week1\", \"station_code\", \"water_flow_week2\", \"water_flow_week3\", \"water_flow_week4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data & Models Loading\n",
    "\n",
    "#### a. Loading of the baseline datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "ds_train = pd.read_csv(f\"{INPUT_DIR}ds_train.csv\")\n",
    "ds_test_spatio_temporal = pd.read_csv(f\"{INPUT_DIR}ds_test_spatio_temporal.csv\")\n",
    "ds_test_temporal = pd.read_csv(f\"{INPUT_DIR}ds_test_temporal.csv\")\n",
    "\n",
    "ds_train[\"ObsDate\"] = pd.to_datetime(ds_train[\"ObsDate\"])\n",
    "ds_test_spatio_temporal[\"ObsDate\"] = pd.to_datetime(ds_test_spatio_temporal[\"ObsDate\"])\n",
    "ds_test_temporal[\"ObsDate\"] = pd.to_datetime(ds_test_temporal[\"ObsDate\"])\n",
    "\n",
    "ds_train = ds_train.set_index(\"ObsDate\")\n",
    "ds_test_spatio_temporal = ds_test_spatio_temporal.set_index(\"ObsDate\")\n",
    "ds_test_temporal = ds_test_temporal.set_index(\"ObsDate\")\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ds_train.drop(columns=TO_DROP)\n",
    "y_train = {}\n",
    "y_train[0] = ds_train[\"water_flow_week1\"]\n",
    "for i in range(1, NUMBER_OF_WEEK):\n",
    "    y_train[i] = ds_train[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "X_test_spatio_temporal = ds_test_spatio_temporal.drop(columns=TO_DROP)\n",
    "y_test_spatio_temporal = {}\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_test_spatio_temporal[i] = ds_test_spatio_temporal[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "X_test_temporal = ds_test_temporal.drop(columns=TO_DROP)\n",
    "y_test_temporal = {}\n",
    "for i in range(0, NUMBER_OF_WEEK):\n",
    "    y_test_temporal[i] = ds_test_temporal[f\"water_flow_week{i+1}\"]\n",
    "\n",
    "mapie_enbpi = {}\n",
    "mapie = {}\n",
    "qrf = {}\n",
    "mapie_aci = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Loading of the model to analyse\n",
    "\n",
    "Models must be trained on 02 Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models based on conditions\n",
    "mapie = []\n",
    "if USE_AUTO_SCAN:\n",
    "    mapie = load_models_auto(\"mapie_quantile\", MODEL_DIR)\n",
    "else:\n",
    "    mapie.append(joblib.load(\"../../models/mapie_quantile_2025-01-17_15-15-04_week0.pkl\"))\n",
    "    mapie.append(joblib.load(\"../../models/mapie_quantile_2025-01-17_15-15-11_week1.pkl\"))\n",
    "    mapie.append(joblib.load(\"../../models/mapie_quantile_2025-01-17_15-15-17_week2.pkl\"))\n",
    "    mapie.append(joblib.load(\"../../models/mapie_quantile_2025-01-17_15-15-17_week3.pkl\"))\n",
    "\n",
    "qrf = []\n",
    "if USE_AUTO_SCAN:\n",
    "    qrf = load_models_auto(\"qrf_quantile\", MODEL_DIR)\n",
    "else:\n",
    "    qrf.append(joblib.load(\"../../models/qrf_quantile_2025-01-17_15-15-04_week0.pkl\"))\n",
    "    qrf.append(joblib.load(\"../../models/qrf_quantile_2025-01-17_15-15-11_week1.pkl\"))\n",
    "    qrf.append(joblib.load(\"../../models/qrf_quantile_2025-01-17_15-15-17_week2.pkl\"))\n",
    "    qrf.append(joblib.load(\"../../models/qrf_quantile_2025-01-17_15-15-17_week3.pkl\"))\n",
    "\n",
    "ebm_ensemble = []\n",
    "if USE_AUTO_SCAN:\n",
    "    ebm_ensemble = load_models_auto(\"ebm_ensemble\", MODEL_DIR)\n",
    "else:\n",
    "    ebm_ensemble.append(joblib.load(\"../../models/EBM_ensemble_2025-01-17_15-15-04_week0.pkl\"))\n",
    "    ebm_ensemble.append(joblib.load(\"../../models/EBM_ensemble_2025-01-17_15-15-11_week1.pkl\"))\n",
    "    ebm_ensemble.append(joblib.load(\"../../models/EBM_ensemble_2025-01-17_15-15-17_week2.pkl\"))\n",
    "    ebm_ensemble.append(joblib.load(\"../../models/EBM_ensemble_2025-01-17_15-15-17_week3.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Performance computation\n",
    "\n",
    "In the following cells we compute performance on the test set defined in the Dataset Split Notebook.\n",
    "\n",
    "#### a. Temporal Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_stations = ds_test_temporal[\"station_code\"].values\n",
    "y_train_stations = ds_train[\"station_code\"].values\n",
    "\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "\n",
    "    print(f\"============================== WEEK {i} temporal ===================================\")\n",
    "    baseline_day_before = ds_test_temporal[\"water_flow_lag_1w\"]\n",
    "    y_pred_mapie, y_pis_mapie = mapie[i].predict(X_test_temporal)\n",
    "    y_pred_qrf = qrf[i].predict(X_test_temporal, quantiles=\"mean\", aggregate_leaves_first=False)\n",
    "    y_pis_qrf = qrf[i].predict(X_test_temporal, quantiles=[ALPHA/2, 1-ALPHA/2])\n",
    "\n",
    "    predictions = [\n",
    "        {\"model\": \"LGBM+MAPIE\", \"prediction\": y_pred_mapie, \"dataset\":\"test\", \"stations\": y_train_stations, \"prediction_interval\": y_pis_mapie},\n",
    "        {\"model\": \"Week before\", \"prediction\": baseline_day_before, \"dataset\":\"test\", \"stations\": y_train_stations, \"prediction_interval\": None},\n",
    "        {\"model\": \"QRF\", \"prediction\": y_pred_qrf, \"dataset\":\"test\", \"stations\": y_train_stations, \"prediction_interval\": y_pis_qrf},\n",
    "    ]\n",
    "\n",
    "\n",
    "    compare_models_per_station(\n",
    "        y_test_temporal[i].values,\n",
    "        predictions,\n",
    "        y_test_stations,\n",
    "        column_to_display=\"log_likelihood\" ,\n",
    "        title = f\"WEEK {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Spatial Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_stations = ds_test_spatio_temporal[\"station_code\"].values\n",
    "\n",
    "for i in range(NUMBER_OF_WEEK):\n",
    "\n",
    "    print(f\"============================== WEEK {i} temporal ===================================\")\n",
    "    baseline_day_before = ds_test_spatio_temporal[\"water_flow_lag_1w\"]\n",
    "    y_pred_mapie, y_pis_mapie = mapie[i].predict(X_test_spatio_temporal)\n",
    "    y_pred_qrf = qrf[i].predict(X_test_spatio_temporal, quantiles=\"mean\", aggregate_leaves_first=False)\n",
    "    y_pis_qrf = qrf[i].predict(X_test_spatio_temporal, quantiles=[ALPHA/2, 1-ALPHA/2])\n",
    "\n",
    "    predictions = [\n",
    "        {\"model\": \"LGBM+MAPIE\", \"prediction\": y_pred_mapie, \"dataset\":\"test\", \"stations\": y_test_stations, \"prediction_interval\": y_pis_mapie},\n",
    "        {\"model\": \"Week before\", \"prediction\": baseline_day_before, \"dataset\":\"test\", \"stations\": y_test_stations, \"prediction_interval\": None},\n",
    "        {\"model\": \"QRF\", \"prediction\": y_pred_qrf, \"dataset\":\"test\", \"stations\": y_test_stations, \"prediction_interval\": y_pis_qrf},\n",
    "    ]\n",
    "\n",
    "\n",
    "    compare_models_per_station(\n",
    "        y_test_spatio_temporal[i].values,\n",
    "        predictions,\n",
    "        y_test_stations,\n",
    "        column_to_display=\"log_likelihood\" ,\n",
    "        title = f\"WEEK {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
